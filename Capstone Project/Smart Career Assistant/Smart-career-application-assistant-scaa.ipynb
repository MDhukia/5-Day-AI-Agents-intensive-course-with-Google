{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13929187,"sourceType":"datasetVersion","datasetId":8876354}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ðŸ“Œ Title: Smart Career Application Assistant (SCAA)\n\nðŸ“˜ 1. Introduction\n\nThe Smart Career Application Assistant (SCAA) is an AI-powered agent designed to help job seekers quickly understand their strengths, improve their resumes, and receive career recommendations. This project uses the Google Agent Development Kit (ADK), Gemini LLM models, and tool integrations to perform resume analysis and provide real-time job market insights.\n\nSCAA automates key stages of the job application process, including skill extraction, job role suggestions, resume improvement tips, salary research, and cover letter generation.\n\nðŸ“˜ 2. Project Objective\n\nMany job seekers struggle to understand:\n\nWhat skills their resume highlights\n\nWhich job roles match their profile\n\nHow to improve their resume\n\nWhat skills are in demand today\nCurrent salary trends\n\nThis project solves these problems with one intelligent agent that analyzes resumes and provides actionable insights within seconds.\n\nðŸ“˜ 3. What This Notebook Demonstrates (Capstone Requirements)\n\nThis notebook implements five ADK concepts (more than the minimum three required):\n\nâœ” 1. LLM-powered agent using Gemini âœ” 2. Built-in ADK Tool: google_search âœ” 3. Custom Tool: Python skill extractor âœ” 4. File processing: Automated PDF resume extraction âœ” 5. Observability: run_debug() call with agent trace\n\nThese features combined form a full, real-world career assistant system.\n\nðŸ“˜ 4. System Workflow Overview\n\nLoad Resume (PDF) from Kaggle input\n\nExtract text using pdfplumber\n\nExtract skills using custom Python tool\n\nSend resume + skills to ADK agent\n\nAgent performs:\n\nResume summary\n\nJob role recommendations\n\nResume improvements\n\ngoogle_search tool call for job market trends\n\nCover letter generation\n\nThis creates a complete AI-driven career analysis pipeline.\n\nðŸ“˜ 5. Tools & Technologies Used\n\nGoogle ADK (Agent Development Kit)\n\nGemini 2.5 Flash Lite\n\ngoogle_search Tool\n\nCustom Python Skill Extractor\n\nPDF text extraction using pdfplumber\n\nInMemoryRunner for debugging & agent flow\n\nKaggle Notebook environment\n\nðŸ“˜ 6. Key Features Implemented\n\nâœ” Resume PDF Upload & Extraction\n\nThe system loads and processes a PDF file directly from the Kaggle dataset.\n\nâœ” Skill Extraction Tool\n\nA custom Python tool extracts relevant technical skills from the resume text.\n\nâœ” Intelligent Agent Reasoning\n\nThe ADK agent analyzes skills and provides smart recommendations.\n\nâœ” Google Search Integration\n\nAgent fetches real-time market insights:\n\nSalary trends\n\nIn-demand skills\n\nJob descriptions\n\nâœ” Cover Letter Generation\n\nThe agent creates a personalized, professional cover letter.\n\nðŸ“˜ 7. Results\n\nThe Smart Career Application Assistant produces:\n\nExtracted skills\n\nThree-point resume summary\n\nRecommended job roles\n\nResume improvement tips\n\nMarket skill demand\n\nSalary insights\n\nAuto-generated cover letter\n\nThese results significantly reduce the time required for job preparation.\n\nðŸ“˜ 8. Conclusion\n\nThe Smart Career Application Assistant (SCAA) demonstrates how a single ADK agent can combine local tools, LLM intelligence, and real-time search to build a practical, high-impact application. This project successfully automates career guidance and highlights the power of intelligent agents for real-world productivity.\n\nðŸ“˜ 9. Future Improvements\n\nAdd multi-agent system (Resume Agent + Salary Agent + Job Match Agent)\n\nIntroduce memory to personalize recommendations over time\n\nDeploy as a web application\n\nAdd PDF section detection (Education, Experience, etc.)\n\nJobâ€“Resume Match Scoring\n\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:36:01.795566Z","iopub.execute_input":"2025-12-01T05:36:01.795851Z","iopub.status.idle":"2025-12-01T05:36:03.869710Z","shell.execute_reply.started":"2025-12-01T05:36:01.795820Z","shell.execute_reply":"2025-12-01T05:36:03.868763Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/resumee/resumeidea.pdf\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!adk web\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T05:36:18.918167Z","iopub.execute_input":"2025-12-01T05:36:18.918478Z","iopub.status.idle":"2025-12-01T06:18:15.091667Z","shell.execute_reply.started":"2025-12-01T05:36:18.918455Z","shell.execute_reply":"2025-12-01T06:18:15.090520Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m85\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m85\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"âœ… GOOGLE_API_KEY loaded\")\nexcept Exception as e:\n    print(\"âŒ Please add GOOGLE_API_KEY in Add-ons â†’ Secrets\")\n    print(\"Details:\", e)\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:18:23.023765Z","iopub.execute_input":"2025-12-01T06:18:23.024565Z","iopub.status.idle":"2025-12-01T06:18:23.093179Z","shell.execute_reply.started":"2025-12-01T06:18:23.024538Z","shell.execute_reply":"2025-12-01T06:18:23.092359Z"}},"outputs":[{"name":"stdout","text":"âœ… GOOGLE_API_KEY loaded\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from google.adk.agents import Agent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import google_search\nfrom google.genai import types\n\nprint(\"âœ… ADK components imported\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:18:29.388519Z","iopub.execute_input":"2025-12-01T06:18:29.389535Z","iopub.status.idle":"2025-12-01T06:18:49.890021Z","shell.execute_reply.started":"2025-12-01T06:18:29.389505Z","shell.execute_reply":"2025-12-01T06:18:49.889305Z"}},"outputs":[{"name":"stdout","text":"âœ… ADK components imported\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"retry_config = types.HttpRetryOptions(\n    attempts=5,\n    exp_base=7,\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504]\n)\n\nprint(\"âœ… Retry configured\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:18:58.766170Z","iopub.execute_input":"2025-12-01T06:18:58.766708Z","iopub.status.idle":"2025-12-01T06:18:58.771758Z","shell.execute_reply.started":"2025-12-01T06:18:58.766685Z","shell.execute_reply":"2025-12-01T06:18:58.771016Z"}},"outputs":[{"name":"stdout","text":"âœ… Retry configured\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import re\n\nSKILLS_DB = [\n    \"python\", \"sql\", \"javascript\", \"java\", \"html\", \"css\",\n    \"pandas\", \"numpy\", \"scikit-learn\", \"tensorflow\", \"pytorch\",\n    \"docker\", \"aws\", \"gcp\", \"azure\",\n    \"tableau\", \"power bi\", \"matplotlib\", \"seaborn\",\n    \"react\", \"node\"\n]\n\ndef extract_skills(text: str):\n    text = text.lower()\n    found = [s for s in SKILLS_DB if s in text]\n    return sorted(set(found))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:06.951822Z","iopub.execute_input":"2025-12-01T06:19:06.952396Z","iopub.status.idle":"2025-12-01T06:19:06.957371Z","shell.execute_reply.started":"2025-12-01T06:19:06.952370Z","shell.execute_reply":"2025-12-01T06:19:06.956497Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"extract_skills(\"I know Python, SQL, AWS, Tableau and React.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:13.535423Z","iopub.execute_input":"2025-12-01T06:19:13.535714Z","iopub.status.idle":"2025-12-01T06:19:13.543212Z","shell.execute_reply.started":"2025-12-01T06:19:13.535691Z","shell.execute_reply":"2025-12-01T06:19:13.542439Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['aws', 'python', 'react', 'sql', 'tableau']"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"career_instruction = \"\"\"\nYou are SmartCareer, an AI assistant for job seekers.\n\nYour responsibilities:\n1. Read user questions or resumes.\n2. Extract important skills and infer likely job roles.\n3. Give 2â€“3 concrete resume improvement tips.\n4. Use the google_search tool whenever you need up-to-date information\n   (skills in demand, salary ranges, market trends, etc.).\n5. Always answer clearly with bullet points and short explanations.\n\nIf the user pastes a resume:\n- First, summarize the profile.\n- Then list skills.\n- Then suggest suitable roles.\n- Then give improvements.\n\"\"\"\n\nroot_agent = Agent(\n    name=\"smart_career_agent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    description=\"Smart Career Application Assistant\",\n    instruction=career_instruction,\n    tools=[google_search],\n)\n\nprint(\"âœ… Smart Career Agent created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:18.509055Z","iopub.execute_input":"2025-12-01T06:19:18.509782Z","iopub.status.idle":"2025-12-01T06:19:18.515276Z","shell.execute_reply.started":"2025-12-01T06:19:18.509760Z","shell.execute_reply":"2025-12-01T06:19:18.514418Z"}},"outputs":[{"name":"stdout","text":"âœ… Smart Career Agent created\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nprint(\"âœ… Runner ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:27.574901Z","iopub.execute_input":"2025-12-01T06:19:27.575240Z","iopub.status.idle":"2025-12-01T06:19:27.580806Z","shell.execute_reply.started":"2025-12-01T06:19:27.575215Z","shell.execute_reply":"2025-12-01T06:19:27.580030Z"}},"outputs":[{"name":"stdout","text":"âœ… Runner ready\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Helper to call the agent\nasync def ask_agent(prompt: str):\n    print(\"Running agent...\\n\")\n    response = await runner.run_debug(prompt)\n    return response\n\n# Safe print for different ADK response shapes\ndef print_final_answer(response):\n    print(\"\\n=== FINAL ANSWER ===\\n\")\n    last_text = None\n\n    if isinstance(response, list):\n          # Look through events from last to first\n        for event in reversed(response):\n            if hasattr(event, \"text\") and event.text:\n                last_text = event.text\n                break\n            elif hasattr(event, \"content\") and event.content:\n                last_text = event.content\n                break\n            elif hasattr(event, \"data\") and isinstance(event.data, dict) and \"text\" in event.data:\n                last_text = event.data[\"text\"]\n                break\n    else:\n        if hasattr(response, \"text\"):\n            last_text = response.text\n        elif hasattr(response, \"content\"):\n            last_text = response.content\n\n    if last_text:\n        print(last_text)\n    else:\n        print(\"âš ï¸ No final text message found in response.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:36.129197Z","iopub.execute_input":"2025-12-01T06:19:36.129533Z","iopub.status.idle":"2025-12-01T06:19:36.136753Z","shell.execute_reply.started":"2025-12-01T06:19:36.129509Z","shell.execute_reply":"2025-12-01T06:19:36.135724Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#Demo 1: General Career Question\nquestion = \"What skills should I highlight for a junior data scientist role in 2025?\"\n\nresponse = await ask_agent(question)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:19:43.999354Z","iopub.execute_input":"2025-12-01T06:19:43.999714Z","iopub.status.idle":"2025-12-01T06:19:50.354879Z","shell.execute_reply.started":"2025-12-01T06:19:43.999689Z","shell.execute_reply":"2025-12-01T06:19:50.354170Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Created new session: debug_session_id\n\nUser > What skills should I highlight for a junior data scientist role in 2025?\nsmart_career_agent > For a junior data scientist role in 2025, you should highlight a blend of strong technical skills, analytical abilities, and effective communication. Here are the key areas to focus on:\n\n**Core Technical Skills:**\n\n*   **Programming Languages:** Proficiency in **Python** is paramount, given its extensive libraries for data manipulation (Pandas, NumPy), statistical analysis, and machine learning (Scikit-learn, TensorFlow, PyTorch). **R** is also highly valued, especially for statistical computing and data visualization. **SQL** is essential for database querying and data management.\n*   **Machine Learning:** A solid understanding of core machine learning concepts and algorithms (e.g., linear regression, logistic regression, decision trees, clustering) is critical. Familiarity with implementing these using libraries like **Scikit-learn** is expected. For more advanced roles, knowledge of **deep learning** frameworks like TensorFlow and PyTorch is beneficial.\n*   **Data Wrangling and Preprocessing:** The ability to clean, transform, and prepare raw data for analysis is a fundamental skill. This includes handling missing values, outliers, and data inconsistencies.\n*   **Data Visualization:** Being able to translate complex data into understandable visual formats is key. Tools like **Matplotlib**, **Seaborn**, **Tableau**, and **Power BI** are commonly used.\n\n**Analytical and Mathematical Skills:**\n\n*   **Statistics and Probability:** A strong foundation in statistical concepts (descriptive statistics, inferential statistics, hypothesis testing) and probability theory is crucial for interpreting data and building robust models.\n*   **Mathematics:** Knowledge of **linear algebra** and **calculus** underpins many machine learning algorithms and optimization techniques.\n\n**Essential Soft Skills and Tools:**\n\n*   **Communication and Storytelling:** The ability to clearly articulate findings to both technical and non-technical audiences is vital for making data-driven recommendations.\n*   **Cloud Platforms:** Familiarity with cloud environments like **AWS**, **Azure**, or **GCP** is increasingly important, as data science work is often done in the cloud. This includes understanding services for data storage, processing, and ML model deployment.\n*   **Version Control (Git):** Essential for collaborative development and tracking code changes.\n*   **Problem-Solving:** A logical and analytical approach to tackle complex data challenges.\n\nBy highlighting these skills on your resume and in interviews, you will demonstrate your readiness for a junior data scientist role in 2025.\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"For a junior data scientist role in 2025, you should highlight a blend of strong technical skills, analytical abilities, and effective communication. Here are the key areas to focus on:\n\n**Core Technical Skills:**\n\n*   **Programming Languages:** Proficiency in **Python** is paramount, given its extensive libraries for data manipulation (Pandas, NumPy), statistical analysis, and machine learning (Scikit-learn, TensorFlow, PyTorch). **R** is also highly valued, especially for statistical computing and data visualization. **SQL** is essential for database querying and data management.\n*   **Machine Learning:** A solid understanding of core machine learning concepts and algorithms (e.g., linear regression, logistic regression, decision trees, clustering) is critical. Familiarity with implementing these using libraries like **Scikit-learn** is expected. For more advanced roles, knowledge of **deep learning** frameworks like TensorFlow and PyTorch is beneficial.\n*   **Data Wrangling and Preprocessing:** The ability to clean, transform, and prepare raw data for analysis is a fundamental skill. This includes handling missing values, outliers, and data inconsistencies.\n*   **Data Visualization:** Being able to translate complex data into understandable visual formats is key. Tools like **Matplotlib**, **Seaborn**, **Tableau**, and **Power BI** are commonly used.\n\n**Analytical and Mathematical Skills:**\n\n*   **Statistics and Probability:** A strong foundation in statistical concepts (descriptive statistics, inferential statistics, hypothesis testing) and probability theory is crucial for interpreting data and building robust models.\n*   **Mathematics:** Knowledge of **linear algebra** and **calculus** underpins many machine learning algorithms and optimization techniques.\n\n**Essential Soft Skills and Tools:**\n\n*   **Communication and Storytelling:** The ability to clearly articulate findings to both technical and non-technical audiences is vital for making data-driven recommendations.\n*   **Cloud Platforms:** Familiarity with cloud environments like **AWS**, **Azure**, or **GCP** is increasingly important, as data science work is often done in the cloud. This includes understanding services for data storage, processing, and ML model deployment.\n*   **Version Control (Git):** Essential for collaborative development and tracking code changes.\n*   **Problem-Solving:** A logical and analytical approach to tackle complex data challenges.\n\nBy highlighting these skills on your resume and in interviews, you will demonstrate your readiness for a junior data scientist role in 2025.\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#Demo 2: Resume Analyzer\nresume_text = \"\"\"\nPriyanka:\nExperienced in Python, SQL, pandas, scikit-learn.\nBuilt dashboards using matplotlib and seaborn.\nUsed Docker to deploy models to cloud.\n\"\"\"\n\nskills = extract_skills(resume_text)\n\nprompt = f\"\"\"\nYou are SmartCareer.\n\nHere is a resume:\n\n{resume_text}\n\nFirst:\n1. Summarize this candidate in 3 short bullet points.\n2. Use this extracted skills list: {skills}\n\nThen:\n3. Suggest 2 suitable job roles and explain why.\n4. Give 3 concrete improvements to the resume.\n5. If helpful, use google_search to check which of these skills are in demand in 2025.\n\"\"\"\n\nresponse = await ask_agent(prompt)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:20:10.210415Z","iopub.execute_input":"2025-12-01T06:20:10.210709Z","iopub.status.idle":"2025-12-01T06:20:16.048856Z","shell.execute_reply.started":"2025-12-01T06:20:10.210690Z","shell.execute_reply":"2025-12-01T06:20:16.047901Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Continue session: debug_session_id\n\nUser > \nYou are SmartCareer.\n\nHere is a resume:\n\n\nPriyanka:\nExperienced in Python, SQL, pandas, scikit-learn.\nBuilt dashboards using matplotlib and seaborn.\nUsed Docker to deploy models to cloud.\n\n\nFirst:\n1. Summarize this candidate in 3 short bullet points.\n2. Use this extracted skills list: ['docker', 'matplotlib', 'pandas', 'python', 'scikit-learn', 'seaborn', 'sql']\n\nThen:\n3. Suggest 2 suitable job roles and explain why.\n4. Give 3 concrete improvements to the resume.\n5. If helpful, use google_search to check which of these skills are in demand in 2025.\n\nsmart_career_agent > Here's an analysis of Priyanka's resume:\n\n**1. Candidate Summary:**\n\n*   Priyanka is a professional with experience in data manipulation, analysis, and machine learning.\n*   She possesses strong programming skills in Python and SQL, along with proficiency in key data science libraries.\n*   She has practical experience in data visualization and deploying models using Docker.\n\n**2. Extracted Skills:**\n\n*   Docker\n*   Matplotlib\n*   Pandas\n*   Python\n*   Scikit-learn\n*   Seaborn\n*   SQL\n\n**3. Suggested Job Roles:**\n\n*   **Junior Data Scientist:** This role aligns directly with the combination of programming, machine learning libraries (scikit-learn), and data visualization skills. The experience with Docker for deployment suggests an understanding of the end-to-end data science lifecycle, which is valuable even at a junior level.\n*   **Data Analyst / Business Intelligence Developer:** The proficiency in SQL, Pandas for data manipulation, and the creation of dashboards using Matplotlib and Seaborn are core requirements for data analyst and BI roles. While she has machine learning experience, these foundational data skills are highly sought after in these positions.\n\n**4. Concrete Resume Improvements:**\n\n*   **Quantify Achievements:** Instead of stating \"Built dashboards,\" quantify the impact. For example, \"Built interactive dashboards using Matplotlib and Seaborn that visualized key performance indicators, leading to a 15% improvement in data-driven decision-making.\"\n*   **Elaborate on Projects:** Briefly describe one or two key projects where these skills were applied. For instance, under a \"Projects\" section, detail a project where Python, scikit-learn, and SQL were used to solve a specific problem, mentioning the outcome.\n*   **Add a Summary/Objective:** Include a concise professional summary at the top of the resume. This should highlight her core competencies and career aspirations, tailoring it to the type of role she is applying for. For example: \"Data professional with 2+ years of experience in data analysis, machine learning, and dashboard development. Seeking to leverage expertise in Python, SQL, and cloud deployment to contribute to innovative data science solutions.\"\n\n**5. Skills in Demand for 2025 (Google Search):**\n\nHere's an assessment of the demand for Priyanka's skills in 2025:\n\n*   **Python, SQL, Pandas, Scikit-learn, Matplotlib, Seaborn:** These are foundational and highly in-demand skills for data science and data analysis roles in 2025. Python remains the most popular programming language for data science due to its extensive libraries. SQL is essential for database management and data extraction. Pandas and Scikit-learn are crucial for data manipulation and machine learning, respectively. Matplotlib and Seaborn are key for data visualization.\n*   **Docker:** Experience with Docker for model deployment is increasingly important, aligning with the growing trend of MLOps (Machine Learning Operations). This skill demonstrates an understanding of how to operationalize machine learning models.\n\nOverall, Priyanka's current skill set is very relevant and in demand for the data science and data analysis job market in 2025.\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"Here's an analysis of Priyanka's resume:\n\n**1. Candidate Summary:**\n\n*   Priyanka is a professional with experience in data manipulation, analysis, and machine learning.\n*   She possesses strong programming skills in Python and SQL, along with proficiency in key data science libraries.\n*   She has practical experience in data visualization and deploying models using Docker.\n\n**2. Extracted Skills:**\n\n*   Docker\n*   Matplotlib\n*   Pandas\n*   Python\n*   Scikit-learn\n*   Seaborn\n*   SQL\n\n**3. Suggested Job Roles:**\n\n*   **Junior Data Scientist:** This role aligns directly with the combination of programming, machine learning libraries (scikit-learn), and data visualization skills. The experience with Docker for deployment suggests an understanding of the end-to-end data science lifecycle, which is valuable even at a junior level.\n*   **Data Analyst / Business Intelligence Developer:** The proficiency in SQL, Pandas for data manipulation, and the creation of dashboards using Matplotlib and Seaborn are core requirements for data analyst and BI roles. While she has machine learning experience, these foundational data skills are highly sought after in these positions.\n\n**4. Concrete Resume Improvements:**\n\n*   **Quantify Achievements:** Instead of stating \"Built dashboards,\" quantify the impact. For example, \"Built interactive dashboards using Matplotlib and Seaborn that visualized key performance indicators, leading to a 15% improvement in data-driven decision-making.\"\n*   **Elaborate on Projects:** Briefly describe one or two key projects where these skills were applied. For instance, under a \"Projects\" section, detail a project where Python, scikit-learn, and SQL were used to solve a specific problem, mentioning the outcome.\n*   **Add a Summary/Objective:** Include a concise professional summary at the top of the resume. This should highlight her core competencies and career aspirations, tailoring it to the type of role she is applying for. For example: \"Data professional with 2+ years of experience in data analysis, machine learning, and dashboard development. Seeking to leverage expertise in Python, SQL, and cloud deployment to contribute to innovative data science solutions.\"\n\n**5. Skills in Demand for 2025 (Google Search):**\n\n\"\"\"\n), Part(\n  text=\"\"\"Here's an assessment of the demand for Priyanka's skills in 2025:\n\n*   **Python, SQL, Pandas, Scikit-learn, Matplotlib, Seaborn:** These are foundational and highly in-demand skills for data science and data analysis roles in 2025. Python remains the most popular programming language for data science due to its extensive libraries. SQL is essential for database management and data extraction. Pandas and Scikit-learn are crucial for data manipulation and machine learning, respectively. Matplotlib and Seaborn are key for data visualization.\n*   **Docker:** Experience with Docker for model deployment is increasingly important, aligning with the growing trend of MLOps (Machine Learning Operations). This skill demonstrates an understanding of how to operationalize machine learning models.\n\nOverall, Priyanka's current skill set is very relevant and in demand for the data science and data analysis job market in 2025.\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#Demo 3: Salary Checker\nprompt = \"\"\"\nUsing google_search, find the typical salary range for a junior data scientist\nin the USA in 2025. Then summarize it in a few bullet points.\n\"\"\"\n\nresponse = await ask_agent(prompt)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:20:35.501656Z","iopub.execute_input":"2025-12-01T06:20:35.501928Z","iopub.status.idle":"2025-12-01T06:20:38.743939Z","shell.execute_reply.started":"2025-12-01T06:20:35.501910Z","shell.execute_reply":"2025-12-01T06:20:38.743264Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Continue session: debug_session_id\n\nUser > \nUsing google_search, find the typical salary range for a junior data scientist\nin the USA in 2025. Then summarize it in a few bullet points.\n\nsmart_career_agent > The typical salary range for a junior data scientist in the USA in 2025 is quite varied, but here's a summary:\n\n*   **Average Total Compensation:** The average total compensation for a junior data scientist in the US can range significantly, with figures from around $72,575 to over $165,000 per year cited.\n*   **Entry-Level Range:** For those with less than one year of experience, salaries are often in the range of $62,947 to $98,650 annually.\n*   **Majority Range:** The majority of junior data scientists can expect to earn between $67,535 and $170,000 annually, depending on the specific role, company, and location.\n*   **Higher End and Top Earners:** Top earners, or those in the 90th percentile, can see salaries reaching up to $243,500 annually. Factors like company, location (major metropolitan areas often pay more), and specific skills can influence where an individual falls within this broad range.\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"The typical salary range for a junior data scientist in the USA in 2025 is quite varied, but here's a summary:\n\n*   **Average Total Compensation:** The average total compensation for a junior data scientist in the US can range significantly, with figures from around $72,575 to over $165,000 per year cited.\n*   **Entry-Level Range:** For those with less than one year of experience, salaries are often in the range of $62,947 to $98,650 annually.\n*   **Majority Range:** The majority of junior data scientists can expect to earn between $67,535 and $170,000 annually, depending on the specific role, company, and location.\n*   **Higher End and Top Earners:** Top earners, or those in the 90th percentile, can see salaries reaching up to $243,500 annually. Factors like company, location (major metropolitan areas often pay more), and specific skills can influence where an individual falls within this broad range.\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#Demo 4: Cover Letter Generator\nname = \"Priyanka\"\ntarget_role = \"Junior Data Scientist\"\nskills_list = extract_skills(resume_text)\n\nprompt = f\"\"\"\nWrite a short, professional cover letter for {name} applying to a {target_role} role.\n\nUse these skills: {skills_list}\n\nStructure:\n- 1 short intro paragraph\n- 1 paragraph about skills + impact\n- 1 closing paragraph\n\nKeep it under 200 words.\n\"\"\"\n\nresponse = await ask_agent(prompt)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:20:52.019208Z","iopub.execute_input":"2025-12-01T06:20:52.019494Z","iopub.status.idle":"2025-12-01T06:20:53.624662Z","shell.execute_reply.started":"2025-12-01T06:20:52.019475Z","shell.execute_reply":"2025-12-01T06:20:53.623788Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Continue session: debug_session_id\n\nUser > \nWrite a short, professional cover letter for Priyanka applying to a Junior Data Scientist role.\n\nUse these skills: ['docker', 'matplotlib', 'pandas', 'python', 'scikit-learn', 'seaborn', 'sql']\n\nStructure:\n- 1 short intro paragraph\n- 1 paragraph about skills + impact\n- 1 closing paragraph\n\nKeep it under 200 words.\n\nsmart_career_agent > Dear [Hiring Manager Name],\n\nI am writing to express my enthusiastic interest in the Junior Data Scientist position at [Company Name], as advertised on [Platform where you saw the advertisement]. With my foundational skills in data analysis, machine learning, and model deployment, I am eager to contribute to your team's success.\n\nMy experience includes proficiency in Python and SQL, coupled with hands-on work using libraries like Pandas for data manipulation, and Scikit-learn for machine learning model development. I have also developed data visualizations using Matplotlib and Seaborn to communicate insights effectively, and have experience deploying models to the cloud using Docker. I am confident in my ability to translate complex data into actionable strategies.\n\nI am excited about the opportunity to apply my skills and grow as a data scientist within a dynamic organization like [Company Name]. Thank you for considering my application. I have attached my resume for your review and welcome the chance to discuss my qualifications further.\n\nSincerely,\nPriyanka\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"Dear [Hiring Manager Name],\n\nI am writing to express my enthusiastic interest in the Junior Data Scientist position at [Company Name], as advertised on [Platform where you saw the advertisement]. With my foundational skills in data analysis, machine learning, and model deployment, I am eager to contribute to your team's success.\n\nMy experience includes proficiency in Python and SQL, coupled with hands-on work using libraries like Pandas for data manipulation, and Scikit-learn for machine learning model development. I have also developed data visualizations using Matplotlib and Seaborn to communicate insights effectively, and have experience deploying models to the cloud using Docker. I am confident in my ability to translate complex data into actionable strategies.\n\nI am excited about the opportunity to apply my skills and grow as a data scientist within a dynamic organization like [Company Name]. Thank you for considering my application. I have attached my resume for your review and welcome the chance to discuss my qualifications further.\n\nSincerely,\nPriyanka\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"### if somebody wants to uploade resume pdf file\n!pip install pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:21:15.469653Z","iopub.execute_input":"2025-12-01T06:21:15.469942Z","iopub.status.idle":"2025-12-01T06:21:21.344402Z","shell.execute_reply.started":"2025-12-01T06:21:15.469923Z","shell.execute_reply":"2025-12-01T06:21:21.343230Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20251107 (from pdfplumber)\n  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20251107->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20251107->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber) (2.23)\nDownloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20251107 pdfplumber-0.11.8 pypdfium2-5.1.0\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from ipywidgets import FileUpload\nimport pdfplumber\n\nupload_widget = FileUpload(accept='.pdf,.txt', multiple=False)\nupload_widget","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:21:33.946010Z","iopub.execute_input":"2025-12-01T06:21:33.946384Z","iopub.status.idle":"2025-12-01T06:21:34.015420Z","shell.execute_reply.started":"2025-12-01T06:21:33.946348Z","shell.execute_reply":"2025-12-01T06:21:34.014472Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"FileUpload(value=(), accept='.pdf,.txt', description='Upload')","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dac7850b98bc40e291c1a4695e8038a1"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/working\"))\nprint(os.listdir(\"../input\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:22:30.685683Z","iopub.execute_input":"2025-12-01T06:22:30.686025Z","iopub.status.idle":"2025-12-01T06:22:30.691484Z","shell.execute_reply.started":"2025-12-01T06:22:30.685998Z","shell.execute_reply":"2025-12-01T06:22:30.690626Z"}},"outputs":[{"name":"stdout","text":"['.virtual_documents']\n['resumee']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import pdfplumber\n\nresume_path = \"/kaggle/input/resumee/resumeidea.pdf\"\n\ndef load_resume_from_pdf(path):\n    try:\n        with pdfplumber.open(path) as pdf:\n            text = \"\"\n            for page in pdf.pages:\n                extracted = page.extract_text()\n                if extracted:\n                    text += extracted + \"\\n\"\n        return text\n    except Exception as e:\n        print(\"Error reading resume:\", e)\n        return None\n\nresume_text = load_resume_from_pdf(resume_path)\n\nprint(\"=== RESUME TEXT EXTRACTED ===\\n\")\nprint(resume_text[:1500])   # show first part only","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:22:37.546663Z","iopub.execute_input":"2025-12-01T06:22:37.546952Z","iopub.status.idle":"2025-12-01T06:22:37.597875Z","shell.execute_reply.started":"2025-12-01T06:22:37.546930Z","shell.execute_reply":"2025-12-01T06:22:37.597144Z"}},"outputs":[{"name":"stdout","text":"=== RESUME TEXT EXTRACTED ===\n\nJohn Doe\nEmail: johndoe@example.com | Phone: (123) 456-7890 | Location: San Jose, CA\nProfessional Summary\nDetail-oriented Data Analyst with experience in data cleaning, visualization, and reporting. Skilled in\nPython, SQL, and Tableau.\nSkills\n(cid:127) Python (cid:127) SQL (cid:127) Tableau (cid:127) Excel (cid:127) Power BI (cid:127) Machine Learning Basics\nExperience\nData Analyst Intern â€” ABC Company (2023â€“2024)\n(cid:127) Analyzed business datasets and built dashboards using Tableau and Power BI.\n(cid:127) Automated data cleaning workflows using Python and Pandas.\n(cid:127) Presented insights that improved decision-making processes.\nEducation\nM.S. in Computer Science, XYZ University (2022â€“2024)\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"skills = extract_skills(resume_text)\nprint(\"Extracted Skills:\", skills)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:23:11.723179Z","iopub.execute_input":"2025-12-01T06:23:11.723739Z","iopub.status.idle":"2025-12-01T06:23:11.728249Z","shell.execute_reply.started":"2025-12-01T06:23:11.723716Z","shell.execute_reply":"2025-12-01T06:23:11.727308Z"}},"outputs":[{"name":"stdout","text":"Extracted Skills: ['pandas', 'power bi', 'python', 'sql', 'tableau']\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"prompt = f\"\"\"\nYou are SmartCareer.\n\nAnalyze this resume:\n\n{resume_text}\n\nExtracted skills: {skills}\n\nTASKS:\n1. Give a 3-bullet summary of this candidate.\n2. Suggest 2â€“3 suitable job roles and explain why.\n3. Provide 3 resume improvement recommendations.\n4. Use google_search to check which of these skills are most in-demand in 2025.\n\"\"\"\n\nresponse = await ask_agent(prompt)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:23:19.211614Z","iopub.execute_input":"2025-12-01T06:23:19.211906Z","iopub.status.idle":"2025-12-01T06:23:26.401269Z","shell.execute_reply.started":"2025-12-01T06:23:19.211884Z","shell.execute_reply":"2025-12-01T06:23:26.400328Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Continue session: debug_session_id\n\nUser > \nYou are SmartCareer.\n\nAnalyze this resume:\n\nJohn Doe\nEmail: johndoe@example.com | Phone: (123) 456-7890 | Location: San Jose, CA\nProfessional Summary\nDetail-oriented Data Analyst with experience in data cleaning, visualization, and reporting. Skilled in\nPython, SQL, and Tableau.\nSkills\n(cid:127) Python (cid:127) SQL (cid:127) Tableau (cid:127) Excel (cid:127) Power BI (cid:127) Machine Learning Basics\nExperience\nData Analyst Intern â€” ABC Company (2023â€“2024)\n(cid:127) Analyzed business datasets and built dashboards using Tableau and Power BI.\n(cid:127) Automated data cleaning workflows using Python and Pandas.\n(cid:127) Presented insights that improved decision-making processes.\nEducation\nM.S. in Computer Science, XYZ University (2022â€“2024)\n\n\nExtracted skills: ['pandas', 'power bi', 'python', 'sql', 'tableau']\n\nTASKS:\n1. Give a 3-bullet summary of this candidate.\n2. Suggest 2â€“3 suitable job roles and explain why.\n3. Provide 3 resume improvement recommendations.\n4. Use google_search to check which of these skills are most in-demand in 2025.\n\nsmart_career_agent > Here's an analysis of John Doe's resume:\n\n**1. Candidate Summary:**\n\n*   John Doe is a recent graduate with a Master's degree in Computer Science, bringing foundational experience as a Data Analyst Intern.\n*   He possesses strong skills in data cleaning, visualization, and reporting, with proficiency in key tools like Python, SQL, Tableau, and Power BI.\n*   His internship experience includes building dashboards and automating data cleaning processes, demonstrating practical application of his skills.\n\n**2. Suitable Job Roles:**\n\n*   **Data Analyst:** This is a direct fit, given his internship experience, proficiency in SQL and visualization tools like Tableau and Power BI, and his ability to present insights. His Python and Pandas skills further enhance his capability for data cleaning and preparation.\n*   **Business Intelligence (BI) Developer:** His experience in building dashboards using Tableau and Power BI, along with presenting insights, directly aligns with the responsibilities of a BI Developer. The automation skills with Python could also be valuable for streamlining BI processes.\n*   **Junior Data Scientist:** While his resume emphasizes data analysis, the \"Machine Learning Basics\" listed in his skills, combined with his Python proficiency, could make him a candidate for entry-level data science roles, especially those that involve significant data wrangling and feature engineering.\n\n**3. Resume Improvement Recommendations:**\n\n*   **Quantify Achievements:** Instead of stating \"Presented insights that improved decision-making processes,\" quantify the impact. For example, \"Presented data-driven insights that led to a 10% reduction in operational costs\" or \"Automated data cleaning workflows using Python and Pandas, saving an estimated 5 hours of manual work per week.\"\n*   **Elaborate on \"Machine Learning Basics\":** Since this is a key differentiator for data science roles, expand on it. Briefly mention any specific algorithms or projects (even academic ones) where he applied basic machine learning concepts. For instance, \"Applied basic machine learning algorithms (e.g., linear regression, k-means clustering) for [specific purpose] during academic projects.\"\n*   **Action-Oriented Language:** Start bullet points with strong action verbs. For example, instead of \"Analyzed business datasets and built dashboards,\" use \"Analyzed business datasets to build interactive dashboards using Tableau and Power BI.\"\n\n**4. Skills in Demand for 2025 (Google Search):**\n\nHere's an analysis of John Doe's resume:\n\n**1. Candidate Summary:**\n\n*   John Doe is a recent graduate with a Master's degree in Computer Science, bringing foundational experience as a Data Analyst Intern.\n*   He possesses strong skills in data cleaning, visualization, and reporting, with proficiency in key tools like Python, SQL, Tableau, and Power BI.\n*   His internship experience includes building dashboards and automating data cleaning processes, demonstrating practical application of his skills.\n\n**2. Suitable Job Roles:**\n\n*   **Data Analyst:** This is a direct fit, given his internship experience, proficiency in SQL and visualization tools like Tableau and Power BI, and his ability to present insights. His Python and Pandas skills further enhance his capability for data cleaning and preparation.\n*   **Business Intelligence (BI) Developer:** His experience in building dashboards using Tableau and Power BI, along with presenting insights, directly aligns with the responsibilities of a BI Developer. The automation skills with Python could also be valuable for streamlining BI processes.\n*   **Junior Data Scientist:** While his resume emphasizes data analysis, the \"Machine Learning Basics\" listed in his skills, combined with his Python proficiency, could make him a candidate for entry-level data science roles, especially those that involve significant data wrangling and feature engineering.\n\n**3. Resume Improvement Recommendations:**\n\n*   **Quantify Achievements:** Instead of stating \"Presented insights that improved decision-making processes,\" quantify the impact. For example, \"Presented data-driven insights that led to a 10% reduction in operational costs\" or \"Automated data cleaning workflows using Python and Pandas, saving an estimated 5 hours of manual work per week.\"\n*   **Elaborate on \"Machine Learning Basics\":** Since this is a key differentiator for data science roles, expand on it. Briefly mention any specific algorithms or projects (even academic ones) where he applied basic machine learning concepts. For instance, \"Applied basic machine learning algorithms (e.g., linear regression, k-means clustering) for [specific purpose] during academic projects.\"\n*   **Action-Oriented Language:** Start bullet points with strong action verbs. For example, instead of \"Analyzed business datasets and built dashboards,\" use \"Analyzed business datasets to build interactive dashboards using Tableau and Power BI.\"\n\n**4. Skills in Demand for 2025 (Google Search):**\n\n*   **SQL:** Consistently cited as a fundamental and highly in-demand skill for data analysts, BI developers, and data scientists in 2025.\n*   **Python:** A crucial programming language for data analysis, automation, and machine learning, with high demand across all data-related roles. Libraries like Pandas, Matplotlib, and Seaborn are also highly valued.\n*   **Tableau and Power BI:** These data visualization and business intelligence tools are essential and in high demand for data analyst and BI developer roles.\n*   **Data Cleaning and Wrangling:** Emphasized as a critical skill for ensuring data accuracy and preparing it for analysis, with demand expected to remain strong.\n*   **Machine Learning Basics:** While not always a primary requirement for junior analyst roles, a foundational understanding of machine learning is increasingly valued, especially for aspiring data scientists.\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"Here's an analysis of John Doe's resume:\n\n**1. Candidate Summary:**\n\n*   John Doe is a recent graduate with a Master's degree in Computer Science, bringing foundational experience as a Data Analyst Intern.\n*   He possesses strong skills in data cleaning, visualization, and reporting, with proficiency in key tools like Python, SQL, Tableau, and Power BI.\n*   His internship experience includes building dashboards and automating data cleaning processes, demonstrating practical application of his skills.\n\n**2. Suitable Job Roles:**\n\n*   **Data Analyst:** This is a direct fit, given his internship experience, proficiency in SQL and visualization tools like Tableau and Power BI, and his ability to present insights. His Python and Pandas skills further enhance his capability for data cleaning and preparation.\n*   **Business Intelligence (BI) Developer:** His experience in building dashboards using Tableau and Power BI, along with presenting insights, directly aligns with the responsibilities of a BI Developer. The automation skills with Python could also be valuable for streamlining BI processes.\n*   **Junior Data Scientist:** While his resume emphasizes data analysis, the \"Machine Learning Basics\" listed in his skills, combined with his Python proficiency, could make him a candidate for entry-level data science roles, especially those that involve significant data wrangling and feature engineering.\n\n**3. Resume Improvement Recommendations:**\n\n*   **Quantify Achievements:** Instead of stating \"Presented insights that improved decision-making processes,\" quantify the impact. For example, \"Presented data-driven insights that led to a 10% reduction in operational costs\" or \"Automated data cleaning workflows using Python and Pandas, saving an estimated 5 hours of manual work per week.\"\n*   **Elaborate on \"Machine Learning Basics\":** Since this is a key differentiator for data science roles, expand on it. Briefly mention any specific algorithms or projects (even academic ones) where he applied basic machine learning concepts. For instance, \"Applied basic machine learning algorithms (e.g., linear regression, k-means clustering) for [specific purpose] during academic projects.\"\n*   **Action-Oriented Language:** Start bullet points with strong action verbs. For example, instead of \"Analyzed business datasets and built dashboards,\" use \"Analyzed business datasets to build interactive dashboards using Tableau and Power BI.\"\n\n**4. Skills in Demand for 2025 (Google Search):**\n\n\"\"\"\n), Part(\n  text=\"\"\"Here's an analysis of John Doe's resume:\n\n**1. Candidate Summary:**\n\n*   John Doe is a recent graduate with a Master's degree in Computer Science, bringing foundational experience as a Data Analyst Intern.\n*   He possesses strong skills in data cleaning, visualization, and reporting, with proficiency in key tools like Python, SQL, Tableau, and Power BI.\n*   His internship experience includes building dashboards and automating data cleaning processes, demonstrating practical application of his skills.\n\n**2. Suitable Job Roles:**\n\n*   **Data Analyst:** This is a direct fit, given his internship experience, proficiency in SQL and visualization tools like Tableau and Power BI, and his ability to present insights. His Python and Pandas skills further enhance his capability for data cleaning and preparation.\n*   **Business Intelligence (BI) Developer:** His experience in building dashboards using Tableau and Power BI, along with presenting insights, directly aligns with the responsibilities of a BI Developer. The automation skills with Python could also be valuable for streamlining BI processes.\n*   **Junior Data Scientist:** While his resume emphasizes data analysis, the \"Machine Learning Basics\" listed in his skills, combined with his Python proficiency, could make him a candidate for entry-level data science roles, especially those that involve significant data wrangling and feature engineering.\n\n**3. Resume Improvement Recommendations:**\n\n*   **Quantify Achievements:** Instead of stating \"Presented insights that improved decision-making processes,\" quantify the impact. For example, \"Presented data-driven insights that led to a 10% reduction in operational costs\" or \"Automated data cleaning workflows using Python and Pandas, saving an estimated 5 hours of manual work per week.\"\n*   **Elaborate on \"Machine Learning Basics\":** Since this is a key differentiator for data science roles, expand on it. Briefly mention any specific algorithms or projects (even academic ones) where he applied basic machine learning concepts. For instance, \"Applied basic machine learning algorithms (e.g., linear regression, k-means clustering) for [specific purpose] during academic projects.\"\n*   **Action-Oriented Language:** Start bullet points with strong action verbs. For example, instead of \"Analyzed business datasets and built dashboards,\" use \"Analyzed business datasets to build interactive dashboards using Tableau and Power BI.\"\n\n**4. Skills in Demand for 2025 (Google Search):**\n\n*   **SQL:** Consistently cited as a fundamental and highly in-demand skill for data analysts, BI developers, and data scientists in 2025.\n*   **Python:** A crucial programming language for data analysis, automation, and machine learning, with high demand across all data-related roles. Libraries like Pandas, Matplotlib, and Seaborn are also highly valued.\n*   **Tableau and Power BI:** These data visualization and business intelligence tools are essential and in high demand for data analyst and BI developer roles.\n*   **Data Cleaning and Wrangling:** Emphasized as a critical skill for ensuring data accuracy and preparing it for analysis, with demand expected to remain strong.\n*   **Machine Learning Basics:** While not always a primary requirement for junior analyst roles, a foundational understanding of machine learning is increasingly valued, especially for aspiring data scientists.\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"prompt = f\"\"\"\nWrite a short, professional cover letter based on this resume:\n\n{resume_text}\n\nUse these skills: {skills}\n\"\"\"\n\nresponse = await ask_agent(prompt)\nprint_final_answer(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T06:23:43.225871Z","iopub.execute_input":"2025-12-01T06:23:43.226224Z","iopub.status.idle":"2025-12-01T06:23:44.476550Z","shell.execute_reply.started":"2025-12-01T06:23:43.226201Z","shell.execute_reply":"2025-12-01T06:23:44.475724Z"}},"outputs":[{"name":"stdout","text":"Running agent...\n\n\n ### Continue session: debug_session_id\n\nUser > \nWrite a short, professional cover letter based on this resume:\n\nJohn Doe\nEmail: johndoe@example.com | Phone: (123) 456-7890 | Location: San Jose, CA\nProfessional Summary\nDetail-oriented Data Analyst with experience in data cleaning, visualization, and reporting. Skilled in\nPython, SQL, and Tableau.\nSkills\n(cid:127) Python (cid:127) SQL (cid:127) Tableau (cid:127) Excel (cid:127) Power BI (cid:127) Machine Learning Basics\nExperience\nData Analyst Intern â€” ABC Company (2023â€“2024)\n(cid:127) Analyzed business datasets and built dashboards using Tableau and Power BI.\n(cid:127) Automated data cleaning workflows using Python and Pandas.\n(cid:127) Presented insights that improved decision-making processes.\nEducation\nM.S. in Computer Science, XYZ University (2022â€“2024)\n\n\nUse these skills: ['pandas', 'power bi', 'python', 'sql', 'tableau']\n\nsmart_career_agent > Dear [Hiring Manager Name],\n\nI am writing to express my strong interest in the [Job Title] position at [Company Name], as advertised on [Platform where you saw the advertisement]. With my Master's degree in Computer Science and practical experience as a Data Analyst Intern, I am well-equipped to contribute to your team.\n\nDuring my internship at ABC Company, I honed my skills in data analysis, visualization, and reporting. I am proficient in Python, SQL, and visualization tools such as Tableau and Power BI, which I used to build dashboards and analyze business datasets. I also automated data cleaning workflows using Python and Pandas, demonstrating my ability to enhance efficiency and accuracy. My experience in presenting data-driven insights has consistently improved decision-making processes.\n\nI am eager to leverage my analytical abilities and technical skills to support [Company Name]'s goals. My resume, attached for your review, provides further detail on my qualifications. Thank you for your time and consideration. I look forward to hearing from you soon.\n\nSincerely,\nJohn Doe\n\n=== FINAL ANSWER ===\n\nparts=[Part(\n  text=\"\"\"Dear [Hiring Manager Name],\n\nI am writing to express my strong interest in the [Job Title] position at [Company Name], as advertised on [Platform where you saw the advertisement]. With my Master's degree in Computer Science and practical experience as a Data Analyst Intern, I am well-equipped to contribute to your team.\n\nDuring my internship at ABC Company, I honed my skills in data analysis, visualization, and reporting. I am proficient in Python, SQL, and visualization tools such as Tableau and Power BI, which I used to build dashboards and analyze business datasets. I also automated data cleaning workflows using Python and Pandas, demonstrating my ability to enhance efficiency and accuracy. My experience in presenting data-driven insights has consistently improved decision-making processes.\n\nI am eager to leverage my analytical abilities and technical skills to support [Company Name]'s goals. My resume, attached for your review, provides further detail on my qualifications. Thank you for your time and consideration. I look forward to hearing from you soon.\n\nSincerely,\nJohn Doe\"\"\"\n)] role='model'\n","output_type":"stream"}],"execution_count":24}]}